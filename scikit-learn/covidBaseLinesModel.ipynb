{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-f910fae0-ba10-4708-9049-670a93f637a9",
    "tags": []
   },
   "source": [
    "- Database: Covid-fake\n",
    "- Function: cleaning\n",
    "- Desp: NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-b7880f68-fb43-45dd-9963-39c76f34c960"
   },
   "source": [
    "# Necessary Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/tathagat/miniconda3/envs/p3/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/tathagat/miniconda3/envs/p3/lib/python3.8/site-packages (from xgboost) (1.21.4)\n",
      "Requirement already satisfied: scipy in /home/tathagat/miniconda3/envs/p3/lib/python3.8/site-packages (from xgboost) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "00002-9b8431e6-7762-485a-9cad-b826b8b2e453",
    "execution_millis": 1610,
    "execution_start": 1602317375718,
    "output_cleared": false,
    "source_hash": "6a0e8856"
   },
   "outputs": [],
   "source": [
    "# Start writing code here...\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import re\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-7462cdd6-7996-40b9-b2ad-4f9db1c30a21"
   },
   "source": [
    "# Read test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "00004-79ce4e19-951f-4d1d-b372-9315510c9e68",
    "execution_millis": 105,
    "execution_start": 1602317380627,
    "output_cleared": false,
    "source_hash": "9f16c2f8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('fake-covid-train.txt')\n",
    "test = pd.read_csv('fake-covid-val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "00005-806e1fa7-a81f-4332-9028-e656062a1e65",
    "execution_millis": 104,
    "execution_start": 1602317385054,
    "output_cleared": false,
    "source_hash": "2ecaabe6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Covid Act Now found \"on average each person in...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>If you tested positive for #COVID19 and have n...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Obama Calls Trump’s Coronavirus Response A Cha...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>???Clearly, the Obama administration did not l...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Retraction—Hydroxychloroquine or chloroquine w...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
       "1   2  States reported 1121 deaths a small rise from ...  real\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
       "4   5  Populous states can generate large case counts...  real\n",
       "5   6  Covid Act Now found \"on average each person in...  real\n",
       "6   7  If you tested positive for #COVID19 and have n...  real\n",
       "7   8  Obama Calls Trump’s Coronavirus Response A Cha...  fake\n",
       "8   9  ???Clearly, the Obama administration did not l...  fake\n",
       "9  10  Retraction—Hydroxychloroquine or chloroquine w...  fake"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "00006-5229c43c-176e-4e28-99ae-4fa40154c8ba",
    "execution_millis": 2,
    "execution_start": 1602317390647,
    "output_cleared": false,
    "source_hash": "3300ffa3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = ['fake','real']\n",
    "def label_encode(val):\n",
    "    return labels.index(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-4e0c86f9-360f-44bb-a346-33a9f60bfa34"
   },
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "00008-d2221d9d-13a4-4124-bcc1-f8e296b9025b",
    "execution_millis": 29,
    "execution_start": 1602317392478,
    "output_cleared": false,
    "source_hash": "4a70d54d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.label = train.label.apply(label_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "00009-27915fb6-5377-4252-b54d-f5ab82228487",
    "execution_millis": 14,
    "execution_start": 1602317413798,
    "output_cleared": false,
    "source_hash": "2ecaabe6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>States reported 1121 deaths a small rise from ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Populous states can generate large case counts...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Covid Act Now found \"on average each person in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>If you tested positive for #COVID19 and have n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Obama Calls Trump’s Coronavirus Response A Cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>???Clearly, the Obama administration did not l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Retraction—Hydroxychloroquine or chloroquine w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet  label\n",
       "0   1  The CDC currently reports 99031 deaths. In gen...      1\n",
       "1   2  States reported 1121 deaths a small rise from ...      1\n",
       "2   3  Politically Correct Woman (Almost) Uses Pandem...      0\n",
       "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...      1\n",
       "4   5  Populous states can generate large case counts...      1\n",
       "5   6  Covid Act Now found \"on average each person in...      1\n",
       "6   7  If you tested positive for #COVID19 and have n...      1\n",
       "7   8  Obama Calls Trump’s Coronavirus Response A Cha...      0\n",
       "8   9  ???Clearly, the Obama administration did not l...      0\n",
       "9  10  Retraction—Hydroxychloroquine or chloroquine w...      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-d9da0c39-f1ea-46d4-9715-9cea25c13fc8"
   },
   "source": [
    "# Cleaning training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": "00011-ef6a747a-1158-4ea4-86ed-def67676f4fb",
    "execution_millis": 339,
    "execution_start": 1602317420342,
    "output_cleared": false,
    "source_hash": "a8298672",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25127/2673429812.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train.tweet = train.tweet.str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = []\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "train.tweet = train.tweet.apply(clean_text)\n",
    "train.tweet = train.tweet.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-da3221db-7d57-4404-8eaf-c8f10ac4c499"
   },
   "source": [
    "### Preparing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "00013-c8cdfe1d-5b09-41d3-8f6b-a7fa5f75ec3b",
    "execution_millis": 164,
    "execution_start": 1602317421233,
    "output_cleared": false,
    "source_hash": "21ef7253"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25127/1926545169.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test.tweet = test.tweet.str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "test.label = test.label.apply(label_encode)\n",
    "test = test.reset_index(drop=True)\n",
    "test.tweet = test.tweet.apply(clean_text)\n",
    "test.tweet = test.tweet.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": "00014-05bed7fb-4f79-4c70-955c-89dfa07c2a32",
    "execution_millis": 6,
    "execution_start": 1602317425170,
    "output_cleared": false,
    "source_hash": "81695e2c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939    #covid testing is done free of cost at govt la...\n",
       "787     for example once a successful vaccine has been...\n",
       "4184    new local restrictions have been announced for...\n",
       "135     _photo of a vaccine developed by us scientists...\n",
       "366     a banner with a swastika trump and pence is fr...\n",
       "1177    #indiafightscorona india has substantively ram...\n",
       "2665    the other  cases are in the community and they...\n",
       "4201    as at  pm th april number of states with confi...\n",
       "6297    daily new cases incidence has changed the risk...\n",
       "558     our partner the cepivaccines is supporting  ca...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tweet.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-5dcf0766-e3b2-4a8e-8354-ce80bf561840"
   },
   "source": [
    "# Base Line Model Used\n",
    "## 1. Naive Bayes\n",
    "## 2. Linear Classifier\n",
    "## 3. Bagging\n",
    "## 4. Boosting\n",
    "## 5. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-a2a07069-13ee-4126-800e-de27e63c8cec"
   },
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": "00017-aaebf049-ddf3-486a-91ba-16883f95c753"
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label,  feature_vector_valid, valid_y,test_data , test_label ,is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    #print(\"In Validation Data\",metrics.accuracy_score(predictions, valid_y))\n",
    "    #applying in test data\n",
    "    predictions_test = classifier.predict(test_data)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions_test = predictions_test.argmax(axis=-1)\n",
    "    print(\"f1 score: \",f1_score(test_label,predictions_test))\n",
    "    print(\"Accuracy: \",metrics.accuracy_score(test_label,predictions_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-b67e4027-7550-4fa0-a3d7-d5074012897e"
   },
   "source": [
    "### 1.Splitting the Data into Train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_id": "00019-c6184073-f974-467e-8520-bd6764ca5d22"
   },
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train['tweet'], train['label'])\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train['tweet'], train['label'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-7f8298a6-60c3-41e8-a6d2-5aa6a2864a0c"
   },
   "source": [
    "### 2. Applying WordLevel tf-idf and bi-gram tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_id": "00021-a0caea99-eab7-4a1a-87b9-a89680f5b1c1"
   },
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(train['tweet'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "test_tfidf   =  tfidf_vect.transform(test['tweet'])\n",
    "\n",
    "# ngram level tf-idf (bigram in this case)\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(train['tweet'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "test_tfidf_ngram   =  tfidf_vect.transform(test['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-37905eed-3943-4f65-ad5b-1f77d5357870"
   },
   "source": [
    "#  Naive Bayes Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "cell_id": "00023-0f9c3c3a-852c-439f-a91d-2b1d2a6d376f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word level tf-idf\n",
      "f1 score:  0.9024390243902439\n",
      "Accuracy:  0.8953271028037383\n",
      "Bigram tf-idf\n",
      "f1 score:  0.5833003561535417\n",
      "Accuracy:  0.5079439252336448\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "print(\"Word level tf-idf\")\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y, test_tfidf, test['label'])\n",
    "# print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"Bigram tf-idf\")\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y ,test_tfidf_ngram, test['label'])\n",
    "# print (\"NB, Bi-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-254e32ab-1b1c-4686-93b0-c544911155a0"
   },
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": "00025-37b71f7a-c63b-4a61-a5e4-a8f2ad512b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word level tf-idf\n",
      "f1 score:  0.9183222958057394\n",
      "Accuracy:  0.9135514018691588\n",
      "Bigram tf-idf\n",
      "f1 score:  0.6333463490823897\n",
      "Accuracy:  0.561214953271028\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "print(\"Word level tf-idf\")\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y, test_tfidf, test['label'])\n",
    "# print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"Bigram tf-idf\")\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(),  xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y ,test_tfidf_ngram, test['label'])\n",
    "# print(\"LR, Bi-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-c735955f-3108-44d2-94ab-8f531fcb466e"
   },
   "source": [
    "# Bagging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "cell_id": "00027-ee51ba23-4c96-47d8-9685-f2f501ed25af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word level tf-idf\n",
      "f1 score:  0.9105332745702954\n",
      "Accuracy:  0.9051401869158878\n",
      "Bigram tf-idf\n",
      "f1 score:  0.23177842565597664\n",
      "Accuracy:  0.5074766355140187\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "print(\"Word level tf-idf\")\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf, valid_y, test_tfidf, test['label'])\n",
    "# print (\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"Bigram tf-idf\")\n",
    "\n",
    "# RF on ngram Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, valid_y ,test_tfidf_ngram, test['label'])\n",
    "# print (\"RF, Bi-gram TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-7b273e95-7405-4d2d-a01f-ab6574b3ca83"
   },
   "source": [
    "# Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "cell_id": "00029-83ccdcac-554b-431a-9ed1-cd6c9a62fc51",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word level tf-idf\n",
      "[16:31:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagat/miniconda3/envs/p3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9087719298245616\n",
      "Accuracy:  0.902803738317757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "print(\"Word level tf-idf\")\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc(), valid_y, test_tfidf.tocsc(), test['label'])\n",
    "# print(\"Xgb, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-bd9ebf0a-d0b4-4fb7-a645-06fa684923bf"
   },
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cell_id": "00031-446b3c68-baec-481e-9c0d-01a5f58c7fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word level tf-idf\n",
      "f1 score:  0.9276520195295161\n",
      "Accuracy:  0.9238317757009346\n",
      "Bigram tf-idf\n",
      "f1 score:  0.5413808870598995\n",
      "Accuracy:  0.5313084112149533\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Word level tf-idf\")\n",
    "#SVM Model on Unigram TF-IDF\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc(), valid_y, test_tfidf.tocsc(), test['label'])\n",
    "# print(\"SVM, WordLevel TF-IDF: \", accuracy)\n",
    "print(\"Bigram tf-idf\")\n",
    "\n",
    "# SVM Model on Bigram TF-IDF\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram.tocsc(), train_y, xvalid_tfidf_ngram.tocsc(), valid_y, test_tfidf_ngram.tocsc(), test['label'])\n",
    "# print(\"SVM, Bi-gram TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00032-805d7b22-27fd-4b76-8136-88f2983811b1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "083d58b7-ade2-4beb-9a11-d89206177ed2",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
